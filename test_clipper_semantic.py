"""
Test Video Clipper v·ªõi ch·∫ø ƒë·ªô Semantic (ASR + ch·ªçn c√¢u hay)
S·ª≠ d·ª•ng Whisper ƒë·ªÉ ph√¢n t√≠ch n·ªôi dung v√† t√¨m highlights th√¥ng minh
"""
import sys
import os

# Setup path
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

from video.clipper import VideoHighlightDetector
from utils.logger import get_logger
import glob

logger = get_logger()

def test_semantic_clipper():
    """Test video clipper v·ªõi semantic mode (ASR)"""
    
    print("=" * 80)
    print("üß† TEST VIDEO CLIPPER - SEMANTIC MODE (ASR + Smart Selection)")
    print("=" * 80)
    print()
    
    # T√¨m video test trong th∆∞ m·ª•c
    test_dirs = [
        "assets/temp/downloads/*.mp4",
        "output/videos/*.mp4",
        "*.mp4"
    ]
    
    video_files = []
    for pattern in test_dirs:
        video_files.extend(glob.glob(pattern))
    
    if not video_files:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y video ƒë·ªÉ test!")
        print("   H√£y t·∫£i m·ªôt video v·ªÅ ho·∫∑c ƒë·∫∑t video .mp4 v√†o th∆∞ m·ª•c g·ªëc")
        print("\nTh·ª≠ t·∫°o video demo...")
        create_demo_video()
        return
    
    # Test v·ªõi video ƒë·∫ßu ti√™n t√¨m th·∫•y
    video_path = video_files[0]
    print(f"üìπ Testing with video: {video_path}")
    print(f"   File size: {os.path.getsize(video_path) / (1024*1024):.2f} MB")
    print()
    
    detector = VideoHighlightDetector(
        min_clip_duration=10,
        max_clip_duration=30
    )
    
    # Test c√°c methods
    methods = [
        ("semantic", "üß† Semantic (Whisper ASR + Smart Selection)"),
        ("audio", "üîä Audio Peaks (Fallback)"),
    ]
    
    for method, description in methods:
        print(f"\n{'='*80}")
        print(f"{description}")
        print(f"{'='*80}")
        
        try:
            highlights = detector.detect_highlights(
                video_path, 
                num_clips=5,
                method=method
            )
            
            if highlights:
                print(f"\n‚úÖ T√¨m th·∫•y {len(highlights)} highlights:\n")
                
                for i, clip in enumerate(highlights, 1):
                    duration = clip['end'] - clip['start']
                    print(f"  Clip #{i}:")
                    print(f"    ‚è±Ô∏è  Time: {clip['start']:.1f}s ‚Üí {clip['end']:.1f}s (duration: {duration:.1f}s)")
                    print(f"    üìä Score: {clip['score']:.3f}")
                    
                    # Hi·ªÉn th·ªã transcript n·∫øu c√≥ (semantic mode)
                    if 'text' in clip and clip['text']:
                        print(f"    üí¨ Text: {clip['text'][:80]}...")
                    print()
                    
            else:
                print(f"‚ùå Kh√¥ng t√¨m th·∫•y highlights v·ªõi method '{method}'")
                
        except Exception as e:
            print(f"\n‚ùå Error with method '{method}': {e}")
            logger.error(f"Test failed: {e}", exc_info=True)
    
    # Cleanup
    detector.cleanup()
    
    print(f"\n{'='*80}")
    print("‚úÖ VIDEO CLIPPER TEST COMPLETED")
    print(f"{'='*80}\n")
    
    print("\nüìù K·∫øt lu·∫≠n:")
    print("  - N·∫øu Semantic mode th√†nh c√¥ng ‚Üí Whisper ƒëang ho·∫°t ƒë·ªông!")
    print("  - N·∫øu fallback to Audio ‚Üí Ki·ªÉm tra video c√≥ audio track kh√¥ng")
    print("  - Highlights v·ªõi 'text' field ‚Üí ASR ƒë√£ ph√¢n t√≠ch n·ªôi dung")
    print()

def create_demo_video():
    """T·∫°o video demo ng·∫Øn ƒë·ªÉ test n·∫øu kh√¥ng c√≥ video"""
    try:
        from moviepy.editor import ColorClip, AudioClip
        import numpy as np
        
        print("\nüé¨ Creating demo video with audio...")
        
        # T·∫°o video m√†u ƒë·ªè 30s
        duration = 30
        clip = ColorClip(size=(640, 480), color=(255, 0, 0), duration=duration)
        
        # Th√™m audio ƒë∆°n gi·∫£n (sine wave)
        def make_frame(t):
            frequency = 440  # A4 note
            return np.sin(2 * np.pi * frequency * t)
        
        audio = AudioClip(make_frame, duration=duration, fps=44100)
        clip = clip.set_audio(audio)
        
        # Save
        output_path = "test_demo_video.mp4"
        clip.write_videofile(
            output_path,
            fps=24,
            codec='libx264',
            audio_codec='aac',
            verbose=False,
            logger=None
        )
        
        print(f"‚úÖ Demo video created: {output_path}")
        print(f"   B√¢y gi·ªù ch·∫°y l·∫°i script n√†y ƒë·ªÉ test!")
        
    except Exception as e:
        print(f"‚ùå Kh√¥ng th·ªÉ t·∫°o demo video: {e}")
        print("   H√£y t·∫£i m·ªôt video v·ªÅ ƒë·ªÉ test")

if __name__ == "__main__":
    # Ki·ªÉm tra xem whisper c√≥ s·∫µn kh√¥ng
    try:
        import whisper
        print("‚úÖ Whisper is installed and ready!")
        print(f"   Version: {whisper.__version__ if hasattr(whisper, '__version__') else 'unknown'}")
        print()
    except ImportError:
        print("‚ö†Ô∏è WARNING: Whisper not installed!")
        print("   Run: pip install openai-whisper")
        print("   Semantic mode will not work without it.\n")
    
    test_semantic_clipper()
