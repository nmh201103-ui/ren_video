import os
import tempfile
import requests
import textwrap
import re
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import (
    AudioFileClip, 
    ImageClip, 
    CompositeAudioClip,
    CompositeVideoClip
)
from gtts import gTTS
from .templates import TEMPLATE_DEFAULT
from utils.logger import get_logger

logger = get_logger()

class VideoRenderer:
    def __init__(self, template=None):
        self.template = template or TEMPLATE_DEFAULT
        self._temp_files = []

    def render(self, processed_data: dict, output_path: str, max_images: int = 10, audio_path: str = None) -> bool:
        try:
            self._ensure_directory(os.path.dirname(output_path))

            # 1. TRUY XU·∫§T D·ªÆ LI·ªÜU ƒêA K√äNH (CH·ªêNG M·∫§T D·ªÆ LI·ªÜU)
            images = processed_data.get("image_urls", [])
            title = str(processed_data.get("title", "S·∫£n ph·∫©m Hot"))
            
            # ∆Øu ti√™n l·∫•y 'description', n·∫øu kh√¥ng c√≥ th√¨ l·∫•y 'short_description'
            desc_raw = processed_data.get("description") or processed_data.get("short_description") or ""
            description = str(desc_raw).strip()

            # --- LOG KI·ªÇM TRA ƒê·∫¶U V√ÄO ---
            print("\n" + "üé¨" * 10 + " [RENDERER PROCESS] " + "üé¨" * 10)
            print(f"TITLE: {title}")
            print(f"M√î T·∫¢ NH·∫¨N ƒê∆Ø·ª¢C: {len(description)} k√Ω t·ª±")
            
            if len(description) < 20:
                logger.warning("‚ö†Ô∏è M√¥ t·∫£ qu√° ng·∫Øn ho·∫∑c r·ªóng, d√πng n·ªôi dung d·ª± ph√≤ng.")
                description = f"Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi {title}. ƒê√¢y l√† s·∫£n ph·∫©m tuy·ªát v·ªùi nh·∫•t v·ªõi ch·∫•t l∆∞·ª£ng v∆∞·ª£t tr·ªôi, gi√° c·∫£ ph·∫£i chƒÉng. ƒê·ª´ng b·ªè l·ª° c∆° h·ªôi s·ªü h·ªØu ngay h√¥m nay!"
            
            print("üé¨" * 30 + "\n")

            # 2. PH√ÇN ƒêO·∫†N M√î T·∫¢ TH√îNG MINH
            # T√°ch theo d·∫•u ch·∫•m, xu·ªëng d√≤ng v√† l·ªçc b·ªè c√¢u qu√° ng·∫Øn
            sentences = [s.strip() for s in re.split(r'[.!?\n]\s*', description) if len(s.strip()) > 10]
            
            if not sentences:
                sentences = textwrap.wrap(description, width=80)

            clips = []
            audio_segments = []
            current_time = 0

            # 3. CLIP TI√äU ƒê·ªÄ (INTRO - 3 GI√ÇY)
            title_clip = self._text_clip(title, 60, "#FFD700", 3.0, animation_type="fade_in")
            title_clip = title_clip.set_start(0)
            clips.append(title_clip)
            current_time += 3.0

            # 4. V√íNG L·∫∂P T·∫†O CLIP ·∫¢NH + GI·ªåNG ƒê·ªåC
            target_images = images[:max_images]
            for i, url in enumerate(target_images):
                # L·∫•y c√¢u m√¥ t·∫£ t∆∞∆°ng ·ª©ng, n·∫øu h·∫øt c√¢u th√¨ d√πng c√¢u cu·ªëi c√πng
                part_text = sentences[i] if i < len(sentences) else sentences[-1]
                
                # T·∫°o Voiceover
                voice_path = self.create_voiceover(part_text)
                if not voice_path:
                    continue
                    
                audio_clip = AudioFileClip(voice_path)
                # Th·ªùi l∆∞·ª£ng clip = ƒë·ªô d√†i gi·ªçng n√≥i + 0.6s ngh·ªâ
                duration = audio_clip.duration + 0.6
                
                # T·∫°o Image Clip v·ªõi Text ch√®n ƒë√®
                img_clip = self.render_image_clip(url, part_text, duration)
                
                if img_clip:
                    # Thi·∫øt l·∫≠p th·ªùi ƒëi·ªÉm b·∫Øt ƒë·∫ßu cho c·∫£ audio v√† video
                    img_clip = img_clip.set_start(current_time)
                    audio_clip = audio_clip.set_start(current_time)
                    
                    clips.append(img_clip)
                    audio_segments.append(audio_clip)
                    
                    current_time += duration
                    logger.info(f"‚úÖ ƒê√£ t·∫°o Clip {i+1}/{len(target_images)}")

            if len(clips) <= 1:
                logger.error("‚ùå Kh√¥ng ƒë·ªß t√†i nguy√™n (·∫£nh/text) ƒë·ªÉ xu·∫•t video.")
                return False

            # 5. MIX AUDIO & EXPORT
            # D√πng CompositeVideoClip ƒë·ªÉ kh·ªõp timeline ch√≠nh x√°c h∆°n concatenate
            final_video = CompositeVideoClip(clips).set_duration(current_time)
            
            voice_audio = CompositeAudioClip(audio_segments)
            
            # Nh·∫°c n·ªÅn (n·∫øu c√≥)
            if audio_path and os.path.exists(audio_path):
                bg_music = AudioFileClip(audio_path).volumex(0.12).set_duration(current_time)
                final_audio = CompositeAudioClip([voice_audio, bg_music])
            else:
                final_audio = voice_audio

            final_video = final_video.set_audio(final_audio)
            
            # Xu·∫•t video ch·∫•t l∆∞·ª£ng cao
            final_video.write_videofile(
                output_path, 
                codec="libx264", 
                audio_codec="aac", 
                fps=24, 
                threads=4, 
                preset="medium",
                logger=None
            )
            
            final_video.close()
            self._cleanup()
            return True

        except Exception as e:
            logger.error(f"‚ùå Render Error: {e}")
            return False

    def render_image_clip(self, url, description, duration):
        try:
            r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
            img = Image.open(BytesIO(r.content)).convert("RGB")
            tw, th = self.template.width, self.template.height
            
            # Canvas ƒëen chu·∫©n TikTok (9:16)
            canvas = Image.new("RGB", (tw, th), (18, 18, 18))
            
            # Resize ·∫£nh s·∫£n ph·∫©m (ƒë·ªÉ ch·ª´a ch·ªó cho text ·ªü d∆∞·ªõi)
            img.thumbnail((tw - 80, th - 600), Image.Resampling.LANCZOS)
            
            # Paste ·∫£nh v√†o gi·ªØa ph·∫ßn tr√™n
            offset = ((tw - img.width) // 2, (th - 600 - img.height) // 2 + 150)
            canvas.paste(img, offset)

            # V·∫Ω Text
            if description:
                draw = ImageDraw.Draw(canvas)
                try: 
                    # ∆Øu ti√™n font Arial, n·∫øu kh√¥ng c√≥ d√πng font m·∫∑c ƒë·ªãnh
                    font = ImageFont.truetype("arial.ttf", 38)
                except: 
                    font = ImageFont.load_default()
                
                # Wrap text ƒë·ªÉ kh√¥ng b·ªã tr√†n m√†n h√¨nh
                wrapped_text = "\n".join(textwrap.wrap(description, width=30))
                
                # CƒÉn l·ªÅ text ·ªü 1/4 d∆∞·ªõi m√†n h√¨nh
                draw.text((tw // 2, th - 300), wrapped_text, fill="white", font=font, anchor="mm", align="center")

            path = self._save_temp(canvas)
            return ImageClip(path, duration=duration).fadein(0.4)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è L·ªói render ·∫£nh {url}: {e}")
            return None

    def create_voiceover(self, text):
        if not text or len(text.strip()) < 2: return None
        try:
            f = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
            tts = gTTS(text=text, lang='vi')
            tts.save(f.name)
            self._temp_files.append(f.name)
            return f.name
        except: return None

    def _text_clip(self, text, size, color, duration, animation_type="none"):
        # T·∫°o clip ti√™u ƒë·ªÅ ngh·ªá thu·∫≠t h∆°n
        tw, th = self.template.width, self.template.height
        img = Image.new("RGB", (tw, th), (25, 25, 25))
        draw = ImageDraw.Draw(img)
        
        try: font = ImageFont.truetype("arial.ttf", size)
        except: font = ImageFont.load_default()
        
        wrapped_text = "\n".join(textwrap.wrap(text, width=22))
        
        # V·∫Ω ti√™u ƒë·ªÅ ·ªü ch√≠nh gi·ªØa m√†n h√¨nh
        draw.text((tw // 2, th // 2), wrapped_text, fill=color, font=font, anchor="mm", align="center")
        
        path = self._save_temp(img)
        clip = ImageClip(path, duration=duration)
        if animation_type == "fade_in": clip = clip.fadein(0.8)
        return clip

    def _save_temp(self, img):
        f = tempfile.NamedTemporaryFile(delete=False, suffix=".jpg")
        img.save(f.name, quality=95)
        self._temp_files.append(f.name)
        return f.name

    def _ensure_directory(self, directory):
        if directory and not os.path.exists(directory):
            os.makedirs(directory)

    def _cleanup(self):
        for f in self._temp_files:
            try:
                if os.path.exists(f): os.remove(f)
            except: pass
        self._temp_files = []