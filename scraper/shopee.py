import re
import time
from typing import Dict, List
from playwright.sync_api import sync_playwright
from scraper.base import BaseScraper
from utils.logger import get_logger

logger = get_logger()

class ShopeeScraper(BaseScraper):
    MAX_DESC_RETRIES = 6
    SCROLL_STEP = 750 

    def scrape(self, url: str) -> Dict:
        logger.info(f"üîó K·∫øt n·ªëi t·ªõi Chrome (9222)...")
        with sync_playwright() as p:
            try:
                browser = p.chromium.connect_over_cdp("http://localhost:9222")
                context = browser.contexts[0]
                page = next((pg for pg in context.pages if "shopee.vn" in pg.url), None)
                if not page:
                    page = context.new_page()

                # C·∫•u h√¨nh User-Agent hi·ªán ƒë·∫°i
                ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
                page.set_extra_http_headers({"User-Agent": ua})

                if url not in page.url:
                    page.goto(url, wait_until="commit", timeout=60000)
                
                # CH·ªú ·∫¢NH LOAD: ƒê·ª£i container ·∫£nh ch√≠nh xu·∫•t hi·ªán
                try:
                    page.wait_for_selector('img[src*="shopee.com"], div[style*="background-image"]', timeout=8000)
                except:
                    pass
                
                page.wait_for_timeout(2500) # Ch·ªù th√™m cho c√°c ·∫£nh lazy-load hi·ªán ra

                # --- B∆Ø·ªöC 1: L·∫§Y ·∫¢NH + TITLE + PRICE NGAY L·∫¨P T·ª®C ---
                title = self._get_title(page) or "S·∫£n ph·∫©m Shopee"
                price = self._get_price(page)
                
                # S·ª≠ d·ª•ng logic n√¢ng cao k·∫øt h·ª£p c·∫£ code c≈© v√† code m·ªõi
                images = self._get_images_advanced(page)
                
                if not images:
                    logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh qua DOM, th·ª≠ qu√©t Regex...")
                    images = self._get_images_regex(page)

                logger.info(f"‚úÖ ƒê√£ l·∫•y xong d·ªØ li·ªáu ƒë·∫ßu trang: {len(images)} ·∫£nh, {title}")

                # --- B∆Ø·ªöC 2: SCROLL XU·ªêNG ƒê·ªÇ L·∫§Y M√î T·∫¢ ---
                description = ""
                for attempt in range(self.MAX_DESC_RETRIES):
                    description = self._get_description_logic(page)
                    if len(description) > 50:
                        logger.info(f"‚úÖ L·∫•y th√†nh c√¥ng m√¥ t·∫£ sau {attempt+1} l·∫ßn scroll.")
                        break
                    
                    logger.info(f"‚ö†Ô∏è ƒêang t√¨m m√¥ t·∫£... (L·∫ßn {attempt+1})")
                    # D√πng mouse.wheel ƒë·ªÉ gi·∫£ l·∫≠p ng∆∞·ªùi d√πng th·∫≠t cu·ªôn trang
                    page.mouse.wheel(0, self.SCROLL_STEP)
                    page.wait_for_timeout(1200)

                # --- B∆Ø·ªöC 3: ƒê√ìNG G√ìI D·ªÆ LI·ªÜU ---
                data = {
                    "title": title,
                    "price": price,
                    "image_urls": images,
                    "description": description if description.strip() else "S·∫£n ph·∫©m tuy·ªát v·ªùi v·ªõi gi√° ∆∞u ƒë√£i c·ª±c t·ªët.",
                    "platform": "shopee",
                    "original_url": url,
                }

                logger.info(f"‚úÖ DONE | ·∫¢nh: {len(data['image_urls'])} | M√¥ t·∫£: {len(data['description'])} k√Ω t·ª±")
                return data

            except Exception as e:
                logger.error(f"‚ùå Scraper Error: {e}")
                return self._empty(url)

    def _get_title(self, page) -> str:
        try:
            # L·∫•y title s·∫°ch nh·∫•t t·ª´ OpenGraph ho·∫∑c page.title()
            og_title = page.evaluate("document.querySelector('meta[property=\"og:title\"]')?.content")
            if og_title: return og_title.split('|')[0].strip()
            return page.title().split('|')[0].strip()
        except: return ""

    def _get_price(self, page) -> str:
        try:
            # Th·ª≠ l·∫•y gi√° t·ª´ metadata tr∆∞·ªõc (lu√¥n ch√≠nh x√°c v√† kh√¥ng b·ªã format l·∫°)
            meta_price = page.evaluate("document.querySelector('meta[property=\"product:price:amount\"]')?.content")
            if meta_price: 
                return f"{int(float(meta_price)):,}‚Ç´".replace(",", ".")
            
            # N·∫øu meta kh√¥ng c√≥, t√¨m tr√™n giao di·ªán
            for selector in [".G27FPX", ".pmmxKx", ".IZPeQz"]:
                price_el = page.locator(selector).first
                if price_el.is_visible():
                    return price_el.inner_text().split('\n')[0].strip()
            return "Gi√° t·ªët"
        except: return "0"

    def _get_images_advanced(self, page) -> List[str]:
        """L·∫•y to√†n b·ªô ·∫£nh s·∫£n ph·∫©m: K·∫øt h·ª£p logic 'usercontent' c≈© v√† 'shopee.com' m·ªõi"""
        return page.evaluate("""() => {
            const results = new Set();
            
            // 1. ∆Øu ti√™n l·∫•y ·∫£nh ƒë·∫°i di·ªán ch√≠nh t·ª´ Meta Tag
            const ogImg = document.querySelector('meta[property="og:image"]')?.content;
            if (ogImg) results.add(ogImg.split('@')[0]);

            // 2. Qu√©t c√°c selectors ·∫£nh s·∫£n ph·∫©m
            const selectors = [
                'div[style*="background-image"]', 
                'img[src*="shopee.com/file/"]', 
                'img[src*="usercontent.com"]',
                '.V63p_R img'
            ];
            
            selectors.forEach(sel => {
                document.querySelectorAll(sel).forEach(el => {
                    let url = '';
                    if (el.tagName === 'IMG') {
                        url = el.getAttribute('data-src') || el.src || '';
                    } else {
                        const bg = el.style.backgroundImage;
                        url = bg.replace(/url\(["']?|["']?\)/g, '');
                    }
                    
                    // L·ªçc b·ªè r√°c
                    if (!url || url.includes('.svg') || url.includes('icon')) return;

                    // Logic l√†m s·∫°ch link ·∫£nh (X·ª≠ l√Ω c·∫£ @ c·ªßa usercontent v√† _tn c·ªßa shopee)
                    // T√°ch @ ƒë·ªÉ l·∫•y link g·ªëc t·ª´ usercontent, t√°ch _ ƒë·ªÉ b·ªè thumbnail t·ª´ shopee
                    let cleanUrl = url.split('@')[0].split('_tn')[0].split('_v')[0];
                    
                    if (!cleanUrl.startsWith('http')) cleanUrl = 'https:' + cleanUrl;
                    
                    if (cleanUrl.includes('shopee.com/file/') || cleanUrl.includes('usercontent.com')) {
                        results.add(cleanUrl);
                    }
                });
            });
            
            return Array.from(results).slice(0, 10);
        }""")

    def _get_images_regex(self, page) -> List[str]:
        try:
            content = page.content()
            # Regex b·∫Øt c·∫£ 2 lo·∫°i domain ·∫£nh
            pattern = r'(?:down-vn\.img\.shopee\.com/file/|cf\.shopee\.vn/file/|down-vn\.img\.shopee\.vn/file/)([a-z0-9A-Z_-]+)'
            matches = re.findall(pattern, content)
            urls = []
            for m in matches:
                if len(m) >= 30: # ID ·∫£nh Shopee th∆∞·ªùng r·∫•t d√†i
                    url = f"https://down-vn.img.shopee.com/file/{m}"
                    if url not in urls: urls.append(url)
            return urls[:10]
        except: return []

    def _get_description_logic(self, page) -> str:
        try:
            # L·∫•y text t·ª´ kh·ªëi section c√≥ ch·ª©a ti√™u ƒë·ªÅ m√¥ t·∫£
            section = page.locator('section:has(h2:has-text("M√î T·∫¢ S·∫¢N PH·∫®M"))').first
            if not section.is_visible():
                # Th·ª≠ t√¨m theo c·∫•u tr√∫c kh√°c n·∫øu c·∫•u tr√∫c tr√™n th·∫•t b·∫°i
                section = page.locator('div:has(> h2:has-text("M√î T·∫¢ S·∫¢N PH·∫®M"))').first
            
            if not section.is_visible(): return ""
            
            raw_text = section.inner_text()
            lines = [l.strip() for l in raw_text.split('\n') if len(l.strip()) > 3]
            
            # Lo·∫°i b·ªè ti√™u ƒë·ªÅ "M√î T·∫¢ S·∫¢N PH·∫®M" ·ªü d√≤ng ƒë·∫ßu ti√™n
            if lines and "M√î T·∫¢ S·∫¢N PH·∫®M" in lines[0].upper():
                lines = lines[1:]
            
            return "\n".join(lines)
        except:
            return ""

    def _empty(self, url: str) -> Dict:
        return {
            "title": "S·∫£n ph·∫©m Shopee",
            "price": "Gi√° t·ªët",
            "image_urls": [],
            "description": "S·∫£n ph·∫©m ch·∫•t l∆∞·ª£ng cao, cam k·∫øt ch√≠nh h√£ng.",
            "platform": "shopee",
            "original_url": url,
        }