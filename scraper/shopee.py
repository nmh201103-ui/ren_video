import re
import time
from typing import Dict, List
from playwright.sync_api import sync_playwright
from scraper.base import BaseScraper
from utils.logger import get_logger

logger = get_logger()

class ShopeeScraper(BaseScraper):
    MAX_DESC_RETRIES = 8  # TÄƒng sá»‘ láº§n thá»­ cuá»™n
    SCROLL_STEP = 1000    # Cuá»™n máº¡nh hÆ¡n Ä‘á»ƒ kÃ­ch hoáº¡t lazy load

    def scrape(self, url: str) -> Dict:
        logger.info(f"ðŸ”— Káº¿t ná»‘i tá»›i Chrome (9222) - URL: {url}")
        with sync_playwright() as p:
            try:
                # Káº¿t ná»‘i browser Ä‘ang má»Ÿ
                browser = p.chromium.connect_over_cdp("http://localhost:9222")
                context = browser.contexts[0]
                
                page = next((pg for pg in context.pages if "shopee.vn" in pg.url), None)
                if not page:
                    page = context.new_page()

                ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
                page.set_extra_http_headers({"User-Agent": ua})

                if url not in page.url:
                    page.goto(url, wait_until="domcontentloaded", timeout=60000)
                
                # Äá»£i trang á»•n Ä‘á»‹nh má»™t chÃºt
                page.wait_for_timeout(3000) 

                # 1. Láº¥y Title vÃ  áº¢nh
                title = self._get_title(page)
                images = self._get_images_advanced(page)

                # 2. CHIáº¾N THUáº¬T QUÃ‰T MÃ” Táº¢ TRIá»†T Äá»‚
                description = ""
                
                # Cá»‘ gáº¯ng tÃ¬m vÃ  báº¥m nÃºt "Xem thÃªm" náº¿u cÃ³ Ä‘á»ƒ Shopee bung full text
                try:
                    expand_button = page.locator('button:has-text("Xem thÃªm"), div:has-text("Xem thÃªm")').last
                    if expand_button.is_visible():
                        expand_button.click(timeout=3000)
                        page.wait_for_timeout(1000)
                except:
                    pass

                for attempt in range(self.MAX_DESC_RETRIES):
                    # Cuá»™n chuá»™t sÃ¢u xuá»‘ng dÆ°á»›i
                    page.mouse.wheel(0, self.SCROLL_STEP)
                    page.wait_for_timeout(1000)
                    
                    description = self._get_description_logic(page)
                    # Náº¿u láº¥y Ä‘Æ°á»£c trÃªn 500 kÃ½ tá»± (mÃ´ táº£ tháº­t thÆ°á»ng dÃ i) thÃ¬ dá»«ng
                    if len(description) > 500:
                        break
                
                # Fallback náº¿u váº«n rá»—ng hoáº·c quÃ¡ ngáº¯n
                if len(description) < 100:
                    logger.warning("âš ï¸ Selector chuyÃªn sÃ¢u tháº¥t báº¡i, láº¥y dá»¯ liá»‡u thÃ´ tá»« Meta hoáº·c Body...")
                    description = self._get_fallback_description(page)

                # 3. LÃ m sáº¡ch nháº¹ nhÃ ng (giá»¯ nguyÃªn cáº¥u trÃºc xuá»‘ng dÃ²ng Ä‘á»ƒ Renderer tÃ¡ch cÃ¢u)
                clean_desc = description.replace("MÃ” Táº¢ Sáº¢N PHáº¨M", "").strip()

                # --- LOG KIá»‚M TRA ---
                print("\n" + "ðŸš€" * 15)
                print(f"[SCRAPER COMPLETED]")
                print(f"Title: {title[:60]}...")
                print(f"áº¢nh: {len(images)} táº¥m")
                print(f"MÃ´ táº£ thu Ä‘Æ°á»£c: {len(clean_desc)} kÃ½ tá»±")
                print("ðŸš€" * 15 + "\n")

                return {
                    "title": title,
                    "image_urls": images,
                    "description": clean_desc,
                    "short_description": clean_desc,
                    "platform": "shopee",
                    "original_url": url
                }

            except Exception as e:
                logger.error(f"âŒ Scraper Error: {e}")
                return self._empty_data(url)

    def _get_description_logic(self, page) -> str:
        try:
            # Cuá»™n Ä‘áº¿n giá»¯a trang Ä‘á»ƒ kÃ­ch hoáº¡t Lazy Load cá»§a pháº§n mÃ´ táº£
            page.evaluate("window.scrollTo(0, document.body.scrollHeight / 3)")
            page.wait_for_timeout(2000)

            return page.evaluate("""() => {
                // 1. TÃ¬m chÃ­nh xÃ¡c Container chá»©a chi tiáº¿t sáº£n pháº©m (Cáº­p nháº­t 2024-2025)
                // Shopee thÆ°á»ng Ä‘áº·t mÃ´ táº£ trong cÃ¡c class cÃ³ cáº¥u trÃºc renderer hoáº·c p_7rWz
                const specificSelectors = [
                    'div.product-detail__renderer', 
                    'div.p_7rWz',
                    '.product-details__section',
                    'div._3yZ_0n'
                ];

                for (let sel of specificSelectors) {
                    const el = document.querySelector(sel);
                    // Náº¿u tÃ¬m tháº¥y vÃ  nÃ³ chá»©a tiÃªu Ä‘á» "MÃ´ táº£ sáº£n pháº©m"
                    if (el && el.innerText.includes("MÃ” Táº¢ Sáº¢N PHáº¨M")) {
                        // Loáº¡i bá» cÃ¡c pháº§n thá»«a náº¿u lá»¡ quÃ©t dÃ­nh (nhÆ° ÄÃ¡nh giÃ¡) báº±ng cÃ¡ch cáº¯t chuá»—i
                        let content = el.innerText.split("ÄÃNH GIÃ Sáº¢N PHáº¨M")[0];
                        return content.trim();
                    }
                }

                // 2. Náº¿u khÃ´ng tÃ¬m tháº¥y báº±ng class, tÃ¬m dá»±a trÃªn tiÃªu Ä‘á» vÄƒn báº£n "MÃ” Táº¢ Sáº¢N PHáº¨M"
                const allElements = document.querySelectorAll('h2, div, section');
                for (let el of allElements) {
                    if (el.innerText === "MÃ” Táº¢ Sáº¢N PHáº¨M" || el.innerText === "Product Description") {
                        // Láº¥y pháº§n tá»­ tiáº¿p theo ngay sau tiÃªu Ä‘á» nÃ y (thÆ°á»ng lÃ  ná»™i dung mÃ´ táº£)
                        const nextEl = el.nextElementSibling || el.parentElement;
                        if (nextEl) return nextEl.innerText.split("ÄÃNH GIÃ Sáº¢N PHáº¨M")[0].trim();
                    }
                }
                return "";
            }""")
        except:
            return ""

    def _get_fallback_description(self, page) -> str:
        """HÃ m dá»± phÃ²ng nhÆ°ng cÃ³ giá»›i háº¡n pháº¡m vi Ä‘á»ƒ trÃ¡nh láº¥y 6000+ kÃ½ tá»± rÃ¡c"""
        try:
            return page.evaluate("""() => {
                const bodyText = document.body.innerText;
                const startKeyword = "MÃ” Táº¢ Sáº¢N PHáº¨M";
                const endKeyword = "ÄÃNH GIÃ Sáº¢N PHáº¨M";
                
                const startIndex = bodyText.indexOf(startKeyword);
                if (startIndex !== -1) {
                    let endIndex = bodyText.indexOf(endKeyword, startIndex);
                    
                    // Náº¿u khÃ´ng tÃ¬m tháº¥y tá»« khÃ³a káº¿t thÃºc, chá»‰ láº¥y tá»‘i Ä‘a 1500 kÃ½ tá»± tá»« Ä‘iá»ƒm báº¯t Ä‘áº§u
                    if (endIndex === -1 || (endIndex - startIndex) > 2500) {
                        endIndex = startIndex + 2000;
                    }
                    
                    let result = bodyText.substring(startIndex, endIndex);
                    // Loáº¡i bá» dÃ²ng tiÃªu Ä‘á» "MÃ” Táº¢ Sáº¢N PHáº¨M" á»Ÿ Ä‘áº§u
                    return result.replace(startKeyword, "").trim();
                }
                
                // Cuá»‘i cÃ¹ng má»›i dÃ¹ng Meta Description (thÆ°á»ng chá»‰ ~150-200 kÃ½ tá»± sáº¡ch)
                return document.querySelector('meta[name="description"]')?.content || "";
            }""")
        except:
            return ""

    def _get_title(self, page) -> str:
        try:
            t = page.title().split('|')[0].strip()
            if not t or t == "Shopee" or len(t) < 5:
                t = page.evaluate("document.querySelector('meta[property=\"og:title\"]')?.content") or "Sáº£n pháº©m Shopee"
            return t
        except:
            return "Sáº£n pháº©m Shopee"

    def _get_images_advanced(self, page) -> List[str]:
        try:
            return page.evaluate("""() => {
                const urls = new Set();
                document.querySelectorAll('img').forEach(img => {
                    let src = img.getAttribute('data-src') || img.src;
                    if (src && (src.includes('usercontent') || src.includes('shopee.com/file/'))) {
                        // Loáº¡i bá» cÃ¡c thumbnail nhá» Ä‘á»ƒ láº¥y áº£nh gá»‘c (@ hoáº·c _tn)
                        let clean = src.split('@')[0].split('_tn')[0].split('_v')[0];
                        if (!clean.startsWith('http')) clean = 'https:' + clean;
                        // Chá»‰ láº¥y cÃ¡c áº£nh cÃ³ váº» lÃ  áº£nh sáº£n pháº©m (kÃ­ch thÆ°á»›c lá»›n)
                        urls.add(clean);
                    }
                });
                return Array.from(urls).slice(0, 10);
            }""")
        except:
            return []

    def _empty_data(self, url: str) -> Dict:
        return {
            "title": "Sáº£n pháº©m Shopee",
            "image_urls": [],
            "description": "",
            "short_description": "",
            "platform": "shopee",
            "original_url": url
        }