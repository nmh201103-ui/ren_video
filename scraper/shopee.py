import re
import json
from typing import Dict, List
from playwright.sync_api import sync_playwright
from scraper.base import BaseScraper
from utils.logger import get_logger

logger = get_logger()

class ShopeeScraper(BaseScraper):
    def scrape(self, url: str) -> Dict:
        logger.info(f"ðŸ”— Káº¿t ná»‘i tá»›i Chrome (9222)...")
        with sync_playwright() as p:
            try:
                browser = p.chromium.connect_over_cdp("http://localhost:9222")
                context = browser.contexts[0]
                page = next((pge for pge in context.pages if "shopee.vn" in pge.url), None)
                if not page:
                    page = context.new_page()

                # Cáº¥u hÃ¬nh Header chá»‘ng bá»‹ cháº·n
                ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
                page.set_extra_http_headers({"User-Agent": ua})

                if url not in page.url:
                    page.goto(url, wait_until="networkidle", timeout=60000)

                # Chá» cho cÃ¡c thÃ nh pháº§n chÃ­nh hiá»‡n ra
                page.wait_for_timeout(2000)
                self._force_load(page)

                # Láº¥y danh sÃ¡ch áº£nh báº±ng nhiá»u cÃ¡ch khÃ¡c nhau
                raw_images = self._get_images(page)
                
                # Náº¿u váº«n khÃ´ng cÃ³ áº£nh, dÃ¹ng phÆ°Æ¡ng phÃ¡p Regex quÃ©t toÃ n bá»™ Source Code
                if not raw_images:
                    logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y áº£nh báº±ng DOM, Ä‘ang thá»­ quÃ©t Regex...")
                    raw_images = self._get_images_regex(page)

                description = self._get_description(page)
                title = self._get_title(page)
                price = self._get_price(page)
                
                data = {
                    "title": title,
                    "price": price,
                    "image_urls": raw_images,
                    "description": description,
                    "platform": "shopee",
                    "original_url": url,
                }
                
                logger.info(f"âœ… Káº¿t quáº£: {len(raw_images)} áº£nh | TiÃªu Ä‘á»: {title[:30]}...")
                return data
            except Exception as e:
                logger.error(f"âŒ Scraper Error: {e}")
                return self._empty(url)

    def _force_load(self, page):
        """Ã‰p trang load áº£nh báº±ng cÃ¡ch cuá»™n chuá»™t vÃ  click xem thÃªm"""
        try:
            page.evaluate("window.scrollTo(0, 800)")
            page.wait_for_timeout(1000)
            # TÃ¬m vÃ  báº¥m nÃºt 'Xem thÃªm' mÃ´ táº£ náº¿u cÃ³
            btn = page.locator('text="Xem thÃªm"').first
            if btn.is_visible():
                btn.click()
        except:
            pass

    def _get_title(self, page) -> str:
        try:
            # Æ¯u tiÃªn láº¥y tá»« Meta tag vÃ¬ nÃ³ luÃ´n cÃ³ vÃ  chuáº©n
            title = page.evaluate("document.querySelector('meta[property=\"og:title\"]')?.content")
            if title: return title.strip()
            
            selectors = ["h1", "._44qnta", "div.hpX4qW span", ".VpY09Z"]
            for s in selectors:
                el = page.locator(s).first
                if el.is_visible(): return el.inner_text().strip()
            return "Sáº£n pháº©m Shopee"
        except: return "Sáº£n pháº©m Shopee"

    def _get_price(self, page) -> str:
        try:
            # Láº¥y giÃ¡ tá»« meta tag Ä‘á»ƒ trÃ¡nh sai sÃ³t giao diá»‡n
            price = page.evaluate("document.querySelector('meta[property=\"product:price:amount\"]')?.content")
            if price: return price
            
            price_el = page.locator(".pq6u9U, .G-uSTW, .p86s3C, ._2Sh_1t").first
            return re.sub(r"\D", "", price_el.inner_text())
        except:
            return "0"

    def _get_images(self, page) -> List[str]:
        """PhÆ°Æ¡ng phÃ¡p 1: QuÃ©t DOM tÃ¬m tháº» img vÃ  picture"""
        return page.evaluate("""() => {
            const urls = new Set();
            
            // Láº¥y áº£nh tá»« cÃ¡c tháº» meta (thÆ°á»ng lÃ  áº£nh Ä‘áº¡i diá»‡n Ä‘áº¹p nháº¥t)
            const ogImg = document.querySelector('meta[property="og:image"]')?.content;
            if (ogImg) urls.add(ogImg.split('@')[0].split('_tn')[0]);

            // QuÃ©t táº¥t cáº£ tháº» img cÃ³ liÃªn quan Ä‘áº¿n sáº£n pháº©m
            document.querySelectorAll('img').forEach(img => {
                const src = img.getAttribute('srcset')?.split(' ')[0] || img.getAttribute('data-src') || img.src;
                if (src && (src.includes('susercontent.com') || src.includes('shopee.vn/file'))) {
                    if (!src.includes('.svg') && !src.includes('icon')) {
                        urls.add(src.split('@')[0].split('_tn')[0].split('_cover')[0]);
                    }
                }
            });
            return Array.from(urls).slice(0, 10);
        }""")

    def _get_images_regex(self, page) -> List[str]:
        """PhÆ°Æ¡ng phÃ¡p 2: QuÃ©t trá»±c tiáº¿p trong Source Code (DÃ¹ng khi DOM bá»‹ áº£o)"""
        try:
            content = page.content()
            # TÃ¬m táº¥t cáº£ cÃ¡c mÃ£ ID áº£nh Shopee (thÆ°á»ng lÃ  chuá»—i hex 32 kÃ½ tá»±)
            img_ids = re.findall(r'vn-11134207-[a-z0-9-]+', content)
            if not img_ids:
                img_ids = re.findall(r'[a-f0-9]{32}', content)
            
            urls = []
            for img_id in set(img_ids):
                if len(img_id) >= 32: # ID áº£nh Shopee chuáº©n dÃ i 32 kÃ½ tá»±
                    urls.append(f"https://down-vn.img.susercontent.com/file/{img_id}")
            
            return urls[:10]
        except:
            return []

    def _get_description(self, page) -> str:
        try:
            # Thá»­ láº¥y tá»« Meta tag description
            meta_desc = page.evaluate("document.querySelector('meta[property=\"og:description\"]')?.content")
            if meta_desc and len(meta_desc) > 50: return meta_desc

            return page.evaluate("""() => {
                const els = Array.from(document.querySelectorAll('div, span, p'))
                    .filter(el => window.getComputedStyle(el).whiteSpace === 'pre-wrap' && el.innerText.length > 50);
                return els.length > 0 ? els[0].innerText : "";
            }""")
        except:
            return ""

    def _empty(self, url: str) -> Dict:
        return {"title": "KhÃ´ng láº¥y Ä‘Æ°á»£c dá»¯ liá»‡u", "price": "0", "image_urls": [], "description": "", "platform": "shopee", "original_url": url}