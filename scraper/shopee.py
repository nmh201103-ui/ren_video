import re
import time
from typing import Dict, List
from playwright.sync_api import sync_playwright
from scraper.base import BaseScraper
from utils.logger import get_logger

logger = get_logger()

class ShopeeScraper(BaseScraper):
    MAX_DESC_RETRIES = 6
    SCROLL_STEP = 900 

    def scrape(self, url: str) -> Dict:
        logger.info(f"ğŸ”— Káº¿t ná»‘i tá»›i Chrome (9222) - URL: {url}")
        with sync_playwright() as p:
            try:
                # Káº¿t ná»‘i browser hiá»‡n táº¡i
                browser = p.chromium.connect_over_cdp("http://localhost:9222")
                context = browser.contexts[0]
                
                # TÃ¬m tab shopee hoáº·c táº¡o má»›i
                page = next((pg for pg in context.pages if "shopee.vn" in pg.url), None)
                if not page:
                    page = context.new_page()

                # Giáº£ láº­p User-Agent xá»‹n
                ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
                page.set_extra_http_headers({"User-Agent": ua})

                # Chuyá»ƒn trang náº¿u cáº§n
                if url not in page.url:
                    page.goto(url, wait_until="domcontentloaded", timeout=60000)
                
                page.wait_for_timeout(2000) 

                # Láº¥y Title vÃ  áº¢nh trÆ°á»›c
                title = self._get_title(page)
                images = self._get_images_advanced(page)

                # --- CHIáº¾N THUáº¬T Láº¤Y MÃ” Táº¢ ÄA Táº¦NG ---
                description = ""
                for attempt in range(self.MAX_DESC_RETRIES):
                    # Cuá»™n chuá»™t Ä‘á»ƒ Shopee render pháº§n Description (Lazy load)
                    page.mouse.wheel(0, self.SCROLL_STEP)
                    page.wait_for_timeout(1200)
                    
                    description = self._get_description_logic(page)
                    if len(description) > 150: # ÄÃ£ láº¥y Ä‘á»§ ná»™i dung dÃ i
                        break
                
                # Fallback: Náº¿u cuá»™n khÃ´ng ra, láº¥y tá»« Meta Description (DÃ¹ ngáº¯n nhÆ°ng váº«n cÃ³ chá»¯)
                if len(description) < 50:
                    logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y selector mÃ´ táº£, thá»­ láº¥y tá»« Meta tags...")
                    description = page.evaluate("document.querySelector('meta[name=\"description\"]')?.content") or ""

                # LÃ m sáº¡ch dá»¯ liá»‡u
                clean_desc = description.replace("MÃ” Táº¢ Sáº¢N PHáº¨M", "").strip()

                # --- LOG XUáº¤T XÆ¯á»NG (XÃC NHáº¬N CHÃNH XÃC KÃ Tá»°) ---
                print("\n" + "ğŸš€" * 15)
                print(f"[SCRAPER SUCCESS]")
                print(f"Title: {title[:50]}...")
                print(f"áº¢nh: {len(images)} táº¥m")
                print(f"MÃ´ táº£ gá»‘c: {len(clean_desc)} kÃ½ tá»±")
                print("ğŸš€" * 15 + "\n")

                # --- ÄÃ“NG GÃ“I Dá»® LIá»†U ÄA KEY (Báº¢O Vá»† Dá»® LIá»†U) ---
                # ChÃºng ta tráº£ vá» cáº£ 2 key Ä‘á»ƒ Renderer khÃ´ng bao giá» bá»‹ rá»—ng
                return {
                    "title": title,
                    "image_urls": images,
                    "description": clean_desc,        # Key chÃ­nh
                    "short_description": clean_desc,  # Key dá»± phÃ²ng cho renderer/main.py
                    "platform": "shopee",
                    "original_url": url,
                    "price": self._get_price_simple(page)
                }

            except Exception as e:
                logger.error(f"âŒ Scraper Error: {e}")
                return self._empty_data(url)

    def _get_description_logic(self, page) -> str:
        try:
            # Ã‰p Shopee hiá»ƒn thá»‹ ná»™i dung báº±ng cÃ¡ch click hoáº·c chá» selector cá»¥ thá»ƒ
            return page.evaluate("""() => {
                // Thá»­ tÃ¬m táº¥t cáº£ cÃ¡c tháº» cÃ³ kháº£ nÄƒng chá»©a mÃ´ táº£
                const selectors = [
                    'div.p_7rWz', 
                    '.product-detail__renderer',
                    'div.product-details__section > font',
                    'div._3yZ_0n',
                    'section:has(h2:has-text("MÃ” Táº¢ Sáº¢N PHáº¨M")) div'
                ];
                
                for (let sel of selectors) {
                    const el = document.querySelector(sel);
                    // Náº¿u tÃ¬m tháº¥y vÃ  ná»™i dung Ä‘á»§ dÃ i thÃ¬ láº¥y
                    if (el && el.innerText.length > 100) return el.innerText;
                }
                return "";
            }""")
        except:
            return ""

    def _get_title(self, page) -> str:
        try:
            t = page.title().split('|')[0].strip()
            if not t or t == "Shopee":
                t = page.evaluate("document.querySelector('meta[property=\"og:title\"]')?.content") or "Sáº£n pháº©m Shopee"
            return t
        except:
            return "Sáº£n pháº©m Shopee"

    def _get_images_advanced(self, page) -> List[str]:
        try:
            return page.evaluate("""() => {
                const urls = new Set();
                // TÃ¬m táº¥t cáº£ áº£nh sáº£n pháº©m, bá» qua cÃ¡c icon nhá»
                document.querySelectorAll('img').forEach(img => {
                    let src = img.getAttribute('data-src') || img.src;
                    if (src && (src.includes('usercontent') || src.includes('shopee.com/file/'))) {
                        // LÃ m sáº¡ch URL Ä‘á»ƒ láº¥y áº£nh gá»‘c cháº¥t lÆ°á»£ng cao
                        let clean = src.split('@')[0].split('_tn')[0].split('_v')[0];
                        if (!clean.startsWith('http')) clean = 'https:' + clean;
                        urls.add(clean);
                    }
                });
                return Array.from(urls).slice(0, 10);
            }""")
        except:
            return []

    def _get_price_simple(self, page) -> str:
        try:
            return page.evaluate("document.querySelector('meta[property=\"product:price:amount\"]')?.content") or "0"
        except:
            return "0"

    def _empty_data(self, url: str) -> Dict:
        return {
            "title": "Sáº£n pháº©m",
            "image_urls": [],
            "description": "Ná»™i dung Ä‘ang cáº­p nháº­t",
            "short_description": "Ná»™i dung Ä‘ang cáº­p nháº­t",
            "platform": "shopee",
            "original_url": url
        }