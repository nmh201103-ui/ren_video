import re
import time
from typing import Dict, List
from io import BytesIO
import requests
from PIL import Image
import numpy as np
from playwright.sync_api import sync_playwright
from scraper.base import BaseScraper
from utils.logger import get_logger

logger = get_logger()

class ShopeeScraper(BaseScraper):
    MAX_DESC_RETRIES = 8  # TÄƒng sá»‘ láº§n thá»­ cuá»™n
    SCROLL_STEP = 1000    # Cuá»™n máº¡nh hÆ¡n Ä‘á»ƒ kÃ­ch hoáº¡t lazy load

    def scrape(self, url: str) -> Dict:
        logger.info(f"ðŸ”— Káº¿t ná»‘i tá»›i Chrome (9222) - URL: {url}")
        with sync_playwright() as p:
            try:
                # Káº¿t ná»‘i browser Ä‘ang má»Ÿ
                browser = p.chromium.connect_over_cdp("http://localhost:9222")
                context = browser.contexts[0]
                
                page = next((pg for pg in context.pages if "shopee.vn" in pg.url), None)
                if not page:
                    page = context.new_page()

                ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
                page.set_extra_http_headers({"User-Agent": ua})

                if url not in page.url:
                    page.goto(url, wait_until="domcontentloaded", timeout=60000)
                
                # Äá»£i trang á»•n Ä‘á»‹nh má»™t chÃºt
                page.wait_for_timeout(3000) 

                # 1. Láº¥y Title, áº¢nh vÃ  GiÃ¡
                title = self._get_title(page)
                images = self._get_images_advanced(page)
                price = self._get_price(page)

                # 2. CHIáº¾N THUáº¬T QUÃ‰T MÃ” Táº¢ TRIá»†T Äá»‚
                description = ""
                
                # Cá»‘ gáº¯ng tÃ¬m vÃ  báº¥m nÃºt "Xem thÃªm" náº¿u cÃ³ Ä‘á»ƒ Shopee bung full text
                try:
                    expand_button = page.locator('button:has-text("Xem thÃªm"), div:has-text("Xem thÃªm")').last
                    if expand_button.is_visible():
                        expand_button.click(timeout=3000)
                        page.wait_for_timeout(1000)
                except:
                    pass

                for attempt in range(self.MAX_DESC_RETRIES):
                    # Cuá»™n chuá»™t sÃ¢u xuá»‘ng dÆ°á»›i
                    page.mouse.wheel(0, self.SCROLL_STEP)
                    page.wait_for_timeout(1000)
                    
                    description = self._get_description_logic(page)
                    # Náº¿u láº¥y Ä‘Æ°á»£c trÃªn 500 kÃ½ tá»± (mÃ´ táº£ tháº­t thÆ°á»ng dÃ i) thÃ¬ dá»«ng
                    if len(description) > 500:
                        break
                
                # Fallback náº¿u váº«n rá»—ng hoáº·c quÃ¡ ngáº¯n
                if len(description) < 100:
                    logger.warning("âš ï¸ Selector chuyÃªn sÃ¢u tháº¥t báº¡i, láº¥y dá»¯ liá»‡u thÃ´ tá»« Meta hoáº·c Body...")
                    description = self._get_fallback_description(page)

                # 3. LÃ m sáº¡ch nháº¹ nhÃ ng (giá»¯ nguyÃªn cáº¥u trÃºc xuá»‘ng dÃ²ng Ä‘á»ƒ Renderer tÃ¡ch cÃ¢u)
                clean_desc = description.replace("MÃ” Táº¢ Sáº¢N PHáº¨M", "").strip()

                # --- LOG KIá»‚M TRA ---
                logger.info('[SCRAPER COMPLETED]')
                logger.info('Title: %s', title[:60])
                logger.info('Images: %d', len(images))
                logger.info('Price: %s', price)
                logger.info('Description length: %d chars', len(clean_desc))

                return {
                    "title": title,
                    "image_urls": images,
                    "description": clean_desc,
                    "short_description": clean_desc,
                    "price": price,
                    "platform": "shopee",
                    "original_url": url
                }

            except Exception as e:
                logger.error(f"âŒ Scraper Error: {e}")
                return self._empty_data(url)

    def _get_description_logic(self, page) -> str:
        try:
            # Cuá»™n Ä‘áº¿n giá»¯a trang Ä‘á»ƒ kÃ­ch hoáº¡t Lazy Load cá»§a pháº§n mÃ´ táº£
            page.evaluate("window.scrollTo(0, document.body.scrollHeight / 3)")
            page.wait_for_timeout(2000)

            return page.evaluate("""() => {
                // 1. TÃ¬m chÃ­nh xÃ¡c Container chá»©a chi tiáº¿t sáº£n pháº©m (Cáº­p nháº­t 2024-2025)
                // Shopee thÆ°á»ng Ä‘áº·t mÃ´ táº£ trong cÃ¡c class cÃ³ cáº¥u trÃºc renderer hoáº·c p_7rWz
                const specificSelectors = [
                    'div.product-detail__renderer', 
                    'div.p_7rWz',
                    '.product-details__section',
                    'div._3yZ_0n'
                ];

                for (let sel of specificSelectors) {
                    const el = document.querySelector(sel);
                    if (el) {
                        const txt = el.innerText || '';
                        const up = txt.toUpperCase();
                        // TÃ¬m cÃ¡c biáº¿n thá»ƒ: "MÃ” Táº¢", "MÃ” Táº¢ Sáº¢N PHáº¨M" hoáº·c "PRODUCT DESCRIPTION"
                        if (up.includes("MÃ” Táº¢") || up.includes("PRODUCT DESCRIPTION")) {
                            // Loáº¡i bá» pháº§n Ä‘Ã¡nh giÃ¡ náº¿u cÃ³
                            let content = txt.split(/ÄÃNH GIÃ Sáº¢N PHáº¨M/i)[0];
                            return content.trim();
                        }
                    }
                }

                // 2. Náº¿u khÃ´ng tÃ¬m tháº¥y báº±ng class, tÃ¬m dá»±a trÃªn tiÃªu Ä‘á» vÄƒn báº£n (case-insensitive)
                const allElements = document.querySelectorAll('h2, div, section, span');
                for (let el of allElements) {
                    const txt = (el.innerText || '').trim();
                    const up = txt.toUpperCase();
                    if (up === "MÃ” Táº¢ Sáº¢N PHáº¨M" || up === "PRODUCT DESCRIPTION" || up.includes('MÃ” Táº¢')) {
                        const nextEl = el.nextElementSibling || el.parentElement;
                        if (nextEl) {
                            let content = nextEl.innerText || '';
                            content = content.split(/ÄÃNH GIÃ Sáº¢N PHáº¨M/i)[0].trim();
                            if (content) return content;
                        }
                    }
                }
                return "";
            }""")
        except:
            return ""

    def _get_fallback_description(self, page) -> str:
        """HÃ m dá»± phÃ²ng nhÆ°ng cÃ³ giá»›i háº¡n pháº¡m vi Ä‘á»ƒ trÃ¡nh láº¥y 6000+ kÃ½ tá»± rÃ¡c
        TÃ¡ch pháº§n logic phá»©c táº¡p Ä‘á»ƒ dá»… unit-test báº±ng Python.
        """
        try:
            # Láº¥y toÃ n bá»™ text cá»§a body tá»« trang
            body_text = page.evaluate("() => document.body.innerText") or ""
            desc = self._extract_description_from_body_text(body_text)
            if desc:
                return desc
            # Náº¿u khÃ´ng cÃ³, thá»­ meta description
            meta = page.evaluate("() => document.querySelector('meta[name=\"description\"]')?.content")
            return meta or ""
        except Exception:
            return ""

    def _extract_description_from_body_text(self, body_text: str) -> str:
        """TÃ¡ch vÃ  tráº£ vá» Ä‘oáº¡n mÃ´ táº£ tá»« body text (case-insensitive)."""
        if not body_text:
            return ""
        body_up = body_text.upper()
        start_idx = body_up.find('MÃ” Táº¢')
        if start_idx == -1:
            start_idx = body_up.find('PRODUCT DESCRIPTION')
        if start_idx != -1:
            end_idx = body_up.find('ÄÃNH GIÃ Sáº¢N PHáº¨M', start_idx)
            if end_idx == -1 or (end_idx - start_idx) > 2500:
                end_idx = start_idx + 2000
            result = body_text[start_idx:end_idx]
            # Loáº¡i bá» cÃ¡c tiÃªu Ä‘á» nhÆ° 'MÃ” Táº¢ Sáº¢N PHáº¨M', 'MÃ” Táº¢' hoáº·c 'PRODUCT DESCRIPTION'
            result = re.sub(r"MÃ” Táº¢ Sáº¢N PHáº¨M", "", result, flags=re.IGNORECASE)
            result = re.sub(r"MÃ” Táº¢", "", result, flags=re.IGNORECASE)
            result = re.sub(r"PRODUCT DESCRIPTION", "", result, flags=re.IGNORECASE)
            return result.strip()
        return ""

    def _get_title(self, page) -> str:
        try:
            t = page.title().split('|')[0].strip()
            if not t or t == "Shopee" or len(t) < 5:
                t = page.evaluate("document.querySelector('meta[property=\"og:title\"]')?.content") or "Sáº£n pháº©m Shopee"
            return t
        except:
            return "Sáº£n pháº©m Shopee"

    def _get_images_advanced(self, page) -> List[str]:
        try:
            raw_urls = page.evaluate("""() => {
                const urls = new Set();
                document.querySelectorAll('img').forEach(img => {
                    let src = img.getAttribute('data-src') || img.src;
                    if (src && (src.includes('usercontent') || src.includes('shopee.com/file/'))) {
                        // Loáº¡i bá» cÃ¡c thumbnail nhá» Ä‘á»ƒ láº¥y áº£nh gá»‘c (@ hoáº·c _tn)
                        let clean = src.split('@')[0].split('_tn')[0].split('_v')[0];
                        if (!clean.startsWith('http')) clean = 'https:' + clean;
                        // Chá»‰ láº¥y cÃ¡c áº£nh cÃ³ váº» lÃ  áº£nh sáº£n pháº©m (kÃ­ch thÆ°á»›c lá»›n)
                        urls.add(clean);
                    }
                });
                return Array.from(urls).slice(0, 15);  // Láº¥y 15 áº£nh Ä‘á»ƒ lá»c
            }""")
            
            # Lá»c áº£nh sáº£n pháº©m thá»±c (loáº¡i bá» banner, voucher, model)
            filtered = self._filter_product_images(raw_urls)
            logger.info(f"ðŸ“¸ Lá»c áº£nh: {len(raw_urls)} -> {len(filtered)} áº£nh sáº£n pháº©m")
            
            return filtered[:10]  # Tráº£ vá» max 10 áº£nh
        except Exception as e:
            logger.error(f"âŒ Failed to get images: {e}")
            return []
    
    def _filter_product_images(self, image_urls: List[str]) -> List[str]:
        """Filter to keep only real product images, remove banners/vouchers/models"""
        filtered = []
        
        for url in image_urls:
            try:
                if self._is_product_image(url):
                    filtered.append(url)
            except Exception as e:
                logger.debug(f"âš ï¸ Failed to check image {url}: {e}")
                # If check fails, keep it (safe default)
                filtered.append(url)
        
        return filtered
    
    def _is_product_image(self, url: str) -> bool:
        """
        Detect if image is real product photo (not banner/voucher/model).
        Returns True if likely a product image.
        """
        try:
            # CRITICAL: Only accept Shopee CDN URLs (block local files)
            if not url.startswith('http'):
                logger.debug(f"âŒ Rejected: Not HTTP URL")
                return False
            
            # Block local file paths that might leak into scraper
            if 'file:///' in url or 'C:/' in url or 'C:' in url or 'Users/' in url:
                logger.debug(f"âŒ Rejected: Local file path")
                return False
            
            # Must be from Shopee CDN
            if not ('usercontent' in url or 'shopee.com/file/' in url or 'shopee' in url.lower()):
                logger.debug(f"âŒ Rejected: Not Shopee CDN")
                return False
            
            # Download image
            response = requests.get(url, timeout=5, stream=True)
            response.raise_for_status()
            img = Image.open(BytesIO(response.content)).convert('RGB')
            
            # 1. Check aspect ratio (banners usually wide, products square-ish)
            width, height = img.size
            aspect_ratio = width / height
            
            # CHá»ˆ loáº¡i bá» banner Cá»°C Ká»² rÃµ rÃ ng (quÃ¡ ngang)
            if aspect_ratio > 8.0 or aspect_ratio < 0.12:
                logger.debug(f"âŒ Rejected: Extreme aspect ratio {aspect_ratio:.2f}")
                return False
            
            # 2. Check size - chá»‰ loáº¡i áº£nh icon cá»±c nhá»
            if width < 100 or height < 100:
                logger.debug(f"âŒ Rejected: Too small {width}x{height}")
                return False
            
            # Táº®T text overlay check - quÃ¡ nhiá»u false positive
            # Táº®T color distribution check - quÃ¡ nhiá»u false positive
            
            return True  # Pass most images
            
        except Exception as e:
            logger.debug(f"âš ï¸ Image check failed: {e}, keeping image")
            return True  # Safe default: keep if unable to check
    
    def _has_heavy_text_overlay(self, img: Image.Image) -> bool:
        """Detect if image has heavy text overlay (banner characteristic)"""
        try:
            # Convert to grayscale
            gray = img.convert('L')
            arr = np.array(gray)
            
            # Detect edges (text has many edges)
            from scipy import ndimage
            edges = ndimage.sobel(arr)
            edge_ratio = np.sum(edges > 40) / arr.size
            
            # If more than 30% of pixels are edges, likely has text
            return edge_ratio > 0.30
            
        except:
            return False  # If detection fails, assume no text
    
    def _is_single_color_dominant(self, img: Image.Image) -> bool:
        """Detect if single color dominates (voucher/icon characteristic)"""
        try:
            # Resize to speed up
            img_small = img.resize((100, 100))
            arr = np.array(img_small)
            
            # Check if one color channel dominates
            r_mean, g_mean, b_mean = arr[:,:,0].mean(), arr[:,:,1].mean(), arr[:,:,2].mean()
            total = r_mean + g_mean + b_mean
            
            # If one channel is > 70% of total, single color dominates
            if max(r_mean, g_mean, b_mean) / total > 0.7:
                return True
            
            # Check color variance
            variance = np.var(arr)
            if variance < 300:  # Low variance = single color
                return True
            
            return False
            
        except:
            return False

    def _empty_data(self, url: str) -> Dict:
        return {
            "title": "Sáº£n pháº©m Shopee",
            "image_urls": [],
            "description": "",
            "short_description": "",
            "price": "0",
            "platform": "shopee",
            "original_url": url
        }

    def _get_price(self, page) -> str:
        """Láº¥y giÃ¡ sáº£n pháº©m tá»« Shopee"""
        try:
            price = page.evaluate("""() => {
                // CÃ¡c selector phá»• biáº¿n cho giÃ¡ trÃªn Shopee
                const priceSelectors = [
                    '.product-price__current-price',           // GiÃ¡ hiá»‡n táº¡i
                    'span.shopee-price__current',              // Class cÅ©
                    '[data-testid="product-price"]',           
                    'div._3I7_6e',                             // Class Shopee 2024-2025
                    'div.shopee-product-rating',              
                    '.product-price'
                ];
                
                for (let sel of priceSelectors) {
                    const el = document.querySelector(sel);
                    if (el) {
                        let text = el.innerText?.trim() || '';
                        // Láº¥y con sá»‘ tá»« text (loáº¡i bá» â‚«, dáº¥u pháº©y, khoáº£ng tráº¯ng)
                        const nums = text.match(/\d+[\d.,]*\d*/);
                        if (nums) {
                            return nums[0].replace(/[.,]/g, '');  // '123.456' -> '123456'
                        }
                    }
                }
                
                // Fallback: tÃ¬m sá»‘ lá»›n nháº¥t trÃªn trang (thÆ°á»ng lÃ  giÃ¡)
                const bodyText = document.body.innerText;
                const pricePattern = /â‚«\s*[\d.,]+/g;
                const matches = bodyText.match(pricePattern);
                if (matches && matches.length > 0) {
                    let price = matches[0].replace(/[â‚«\s.,]/g, '');
                    // Lá»c Ä‘á»ƒ chá»‰ láº¥y giÃ¡ há»£p lÃ½ (1000-999999999)
                    if (price.length >= 4 && price.length <= 9) {
                        return price;
                    }
                }
                
                return '0';
            }""")
            return price or '0'
        except Exception as e:
            logger.debug(f"âš ï¸ Failed to get price: {e}")
            return '0'